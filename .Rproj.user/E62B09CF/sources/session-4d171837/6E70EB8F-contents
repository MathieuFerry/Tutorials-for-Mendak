library(shiny)
library(DT)
library(sortable)
library(tidyverse)
library(ggplot2)
library(quanteda)
library(rainette)
library(wordcloud)
library(dplyr)
library(readxl)
library(writexl)
library(quanteda.textplots)
library(quanteda.textstats)
library(FactoMineR)
library(ggrepel)
library(paletteer)

#For lemmatization... see if we keep it here
library(udpipe)



# UI
ui <- fluidPage(
  
  tags$script("
  Shiny.addCustomMessageHandler('datasetUpdated', function(message) {
    Shiny.onInputChange('datasetTrigger', Math.random());
  });
"),
  
  
  navbarPage("Mendak",
             theme = bslib::bs_theme(bootswatch = "sandstone"),
             
             # Welcome ------------------
             tabPanel("Welcome",
                      
                      HTML("<title>Welcome to Mendak</title>
</head>
<body>
    <h1>Welcome to Mendak</h1>
    <p>This shiny app is made for (simple) data and textual statistical analysis. The app is divided into three functional tabs of interest:</p>
    <ul>
        <li>
            <strong>Data Management tab:</strong> Upload and format your dataset (you can upload it in different formats but it has to be a row x column dataset, where one of the columns contains your text to be analysed). If you do not have a ready-made dataset, use the sample dataset.
        </li>
        <li>
            <strong>Descriptive Statistics tab:</strong> Run univariate and bivariate statistics on the quantitative and qualitative variables of the dataset.
        </li>
        <li>
            <strong>Textual Analysis tab:</strong> Clean and analyse the text corpus contained in one of the columns of the dataset. Different analyses can be conducted and in case a cluster analysis is conducted, new variable(s) can be added to the dataset to be analysed in the Descriptive Statistics tab.
        </li>
    </ul>
    <p>This shiny app has been written to facilitate statistical analyses for non-R users (and non-coders). The logic follows the tutorials <a href='https://mathieuferry.github.io/PondicherryWorkshop/'>here</a> to conduct these analyses in the R console. I will update this page with a link to a tutorial as soon as it is ready.</p>
    <center><img src='https://cdn.pixabay.com/photo/2020/06/20/01/24/frog-5319326_1280.jpg' width='700' 
     height='500' alt='A nice and funny picture of a frog' ></center>

                           </body>")
             ),
             navbarMenu("Data Management",
                        tabPanel("Upload and Download",
                                 sidebarLayout(
                                   sidebarPanel(
                                     fileInput("file1", "Choose File", accept = c(".csv", ".xls", ".xlsx", ".rdata", ".rds")),
                                     actionButton("load_sample", "Load Sample Data"),
                                     selectInput("export_format", "Export Format:", choices = c("csv", "xls", "xlsx", "rdata", "rds")),
                                     downloadButton("downloadData", "Download Data")
                                   ),
                                   mainPanel(
                                     verbatimTextOutput("data_summary"),
                                     uiOutput("variable_management")
                                   )
                                 )
                        ),
                        tabPanel("View",
                                 DTOutput("data_view")
                        )
                        
             ),
             
             
             
             # UI Descriptive stat analysis ---------------------
             navbarMenu("Descriptive statistics",
                        
                        tabPanel("Univariate",
                                 sidebarLayout(
                                   sidebarPanel(
                                     uiOutput("var_select_uni"),
                                     uiOutput("var_calc_uni")
                                     
                                   ),
                                   mainPanel(
                                     DTOutput("univariate_table"),
                                     plotOutput("univariate_plot")
                                   )
                                 )
                        ),
                        tabPanel("Bivariate",
                                 sidebarLayout(
                                   sidebarPanel(
                                     uiOutput("var_select_bi"),
                                     uiOutput("var_select_bi_exp"),
                                     uiOutput("display_option")
                                     
                                   ),
                                   mainPanel(
                                     DTOutput("bivariate_table"),
                                     plotOutput("bivariate_plot")
                                   )
                                 )
                        )
             ),
             
             #UI textual -------------------
             navbarMenu("Textual Analysis",
                        tabPanel("Text Cleaning",
                                 sidebarLayout(
                                   sidebarPanel(
                                     uiOutput("text_var_select"),
                                     uiOutput("text_cleaning_options"),
                                     uiOutput("minwordsize"),
                                     uiOutput("minwordsmention"),
                                     uiOutput("minwordsegment"),
                                     actionButton("clean_text", "Clean Text")
                                   ),
                                   mainPanel(
                                     tabsetPanel(
                                       tabPanel("Summary statistics",
                                                verbatimTextOutput("corpus_summary")
                                       ),
                                       ##Here: add number of features by document
                                       ##Number of segments in each document
                                       tabPanel("Frequency of cleaned features",
                                                DTOutput("freq_terms_table")
                                       ),
                                       tabPanel("Word cloud",
                                                sliderInput("maxwords", "Maximum number of words to plot", min = 50, max = 1000, value = 100),
                                                plotOutput("wordcloud")
                                       )
                                     )
                                   )
                                 )
                        ),
                        
                        #UI dual word cloud -------------------
                        
                        tabPanel("Dual word cloud",
                                 sidebarLayout(
                                   sidebarPanel(
                                     uiOutput("wordcloud_var_select"),
                                     uiOutput("factor_level_select"),
                                     actionButton("confirm", "Confirm Selection")
                                     
                                   ),
                                   mainPanel(
                                     tabsetPanel(
                                       tabPanel("Plot",
                                                sliderInput("maxdualwords", "Maximum number of words to plot", min = 20, max = 1000, value = 100),
                                                plotOutput("dualwordcloud_plot",width = "100%",
                                                           height = "800px")
                                       ),
                                       tabPanel("Table",
                                                
                                                p("The most distinctive terms to each category are based on a 'keyness' score, here calculated from the chi-squared value (and associated p-value)."),
                                                p("A high positive chi-squared value is distinctive of features of the 'top' category, whereas a low negative chi-squared value is distinctive of the 'bottom' category (from the word cloud)"),
                                                sliderInput("maxkeyness", "Maximum number of characteristic words to show", min = 1, max = 50, value = 20),
                                                
                                                DTOutput("dualfreq_terms_tableTop"),
                                                DTOutput("dualfreq_terms_tableBttm"),
                                       )
                                     )
                                   )
                                 ) ),
                        #UI Stratified Frequency -------------------
                        
                        tabPanel("Stratified Occurrences",
                                 sidebarLayout(
                                   sidebarPanel(
                                     selectInput("strat_var_forfreq", "Stratification Variable", choices = NULL),
                                     selectInput("word_choice_forfreq", "Word Choice", choices = NULL),
                                     actionButton("compute_strat_freq", "Compute Stratified Frequency")
                                   ),
                                   mainPanel(
                                     DTOutput("strat_freq_table")
                                   )
                                 )
                        ),
                        
                        # UI Context -----------
                        tabPanel("Context",
                                 sidebarLayout(
                                   
                                   sidebarPanel(
                                     uiOutput("word_to_search"),
                                     actionButton("search_context", "Confirm Selection")
                                   ),
                                   mainPanel(
                                     DTOutput("table_context")
                                   ) 
                                 )),
                        
                        # UI Cooccurrences -----------
                        
                        tabPanel("Co-occurrences",
                                 sidebarLayout(
                                   
                                   sidebarPanel(
                                     uiOutput("what_to_coocc"),
                                     uiOutput("level_toocc"),
                                     actionButton("display_coocc", "Display")
                                   ),
                                   mainPanel(
                                     plotOutput("plot_coocc",width = "100%",
                                                height = "800px")
                                   ) 
                                 )
                        ),
                        
                        
                        #Text Classification -------------------
                        
                        tabPanel("Classification",
                                 sidebarLayout(
                                   sidebarPanel(
                                     radioButtons("whatclass","Cluster unit of analysis:",c("Documents","Segments"),selected="Documents"),
                                     conditionalPanel(condition = "input.whatclass == 'Segments'",
                                                      radioButtons("howclass","Reinert's algorithm:",c("Simple Descendant Hierarchical Classification","Dual Descendant Hierarchical Classification"),selected="Simple Descendant Hierarchical Classification")
                                                      ,
                                                      conditionalPanel(
                                                        condition = "input.howclass == 'Simple Descendant Hierarchical Classification'",
                                                        sliderInput("minseg_simple", "Minimal number of cleaned features per segment", min = 0, max = 200, value = 10)
                                                      ),
                                                      conditionalPanel(
                                                        condition = "input.howclass == 'Dual Descendant Hierarchical Classification'",
                                                        sliderInput("minseg_dual1", "Minimal number of cleaned features per segment for first clustering", min = 0, max = 200, value = 10),
                                                        sliderInput("minseg_dual2", "Minimal number of cleaned features per segment for second clustering", min = 0, max = 200, value = 15)
                                                        
                                                      )),
                                     
                                     sliderInput("maxk", "Number of clusters to compute", min = 2, max = 10, value = 6),
                                     actionButton("classify", "Classify"),
                                     
                                     br(),
                                     textInput("new_var_name_class", "New Cluster Variable Name"),
                                     actionButton("add_var", "Add Cluster Variable in the Dataset")
                                   ),
                                   mainPanel(
                                     tabsetPanel(
                                       tabPanel("Classes",
                                                numericInput("maxfeatshow", "Max number of terms to display by cluster:", 10, min = 1, max = 100),
                                                
                                                plotOutput("dendrogram")
                                       ),
                                       tabPanel("Documents/Segments by class",
                                                uiOutput("class_selector"),
                                                textInput("search_word", "Filter documents (type to search):", ""),
                                                
                                                tableOutput("document_table")
                                                
                                       ),
                                       tabPanel("Correspondance Analysis",
                                                
                                                HTML("A Correspondance Analysis is run on the matrix 'clusters x features', where we keep only the most positively-associated features of each cluster (using the chi2 measure). 
                                                     This analysis is similar to the one that can be obtained from Iramuteq.
                                                     We attribute words to one cluster (and color them accordingly) based on how the highest positive association in a given cluster.
                                                     Correspondance analysis helps vizualise how distinct clusters are from each other, particularly when running Dual Clustering, where we cannot vizualise the dendrogram."),
                                                
                                                uiOutput("correspondance_selector"),
                                                
                                                plotOutput("AFC")
                                                
                                       )
                                     )
                                   )
                                 )
                        )
                        
             ),
             #About -----------------------
             tabPanel("About",
                      h3("About Mendak"),
                      HTML("<p>Mendak is the acronym of 'My Easy-to-use Navigator for Data Analysis and Klustering.' 
                      It also means frog in Hindi (मेंढक). It is a playful nod to 'rainette' (literally, treefrog in French),
                      the R package developed by Julien Barnier.  It implements the classification
                      algorithm for textual analysis based on Reinert's method. Max Reinert was a data engineer at <a href='https://www.printemps.uvsq.fr/'>Printemps (UVSQ)</a>, 
                           my current research lab (more info about me <a href='https://mathieuferry.github.io/'>here</a>).</p>
                           
                      <p>Reinert's method is highly effective for classifying text documents and is less statistically 
                        intensive in textual analysis compared to the powerful algorithms of modern AI that now surround
                        us. However, it has been challenging to access. Existing softwares (Alceste, Iramuteq) require installation on 
                        a local computer, unlike some alternative tools that also employ 'Benzécri's cookbook' (the French 
                        approach to data analysis based on geometric data analysis) to textual analysis, such as Hyperbase (where however no solution of clustering is available)</p>
                        
                      <p>The recent release of the 'rainette' package was a significant development, enabling the implementation
                        of Reinert's classification algorithm in R. This facilitated the beta development of this Shiny app, designed 
                        for non-coders to use it online—a crucial factor for its adoption by more 'qualitative' social scientists. The app
                        is designed to streamline textual data analysis and includes functions for conducting univariate and 
                        bivariate statistical analyses, further enhancing its utility.</p>
                      <p>The app uses different key R packages for textual analysis: <a href='https://quanteda.io/'>quanteda</a>, <a href='https://lindat.mff.cuni.cz/services/udpipe/'>udpipe</a> and <a href='https://juba.github.io/rainette/'>rainette</a></p>
                      <p>For any question or remark, please send an email to mathieu.ferry[at]uvsq.fr.</p>")
                      
                      
             )
  )
)

# Server
server <- function(input, output, session) {
  `%||%` <- function(x, y) if (is.null(x)) y else x
  
  dataset <- reactiveVal(NULL)
  var_info <- reactiveVal(NULL)
  
  # Function to read various file formats
  read_file <- function(file) {
    ext <- tools::file_ext(file$datapath)
    switch(ext,
           csv = read.csv(file$datapath),
           xls = read_excel(file$datapath),
           xlsx = read_excel(file$datapath),
           rdata = get(load(file$datapath)),
           rds = readRDS(file$datapath),
           stop("Unsupported file format")
    )
  }
  
  # Function to detect variable types
  detect_var_types <- function(data) {
    sapply(data, function(x) {
      if (is.numeric(x)) {
        return("numeric")
      } else if (is.character(x) || is.factor(x)) {
        if (mean(nchar(as.character(x))) < 50) {
          return("factor")
        } else {
          return("character")
        }
      } else {
        return("other")
      }
    })
  }
  
  # Load data
  observeEvent(input$file1, {
    req(input$file1)
    tryCatch({
      data <- read_file(input$file1)
      var_types <- detect_var_types(data)
      for (col in names(data)) {
        if (var_types[col] == "factor") {
          data[[col]] <- as.factor(data[[col]])
        } else if (var_types[col] == "character") {
          data[[col]] <- as.character(data[[col]])
        }
      }
      dataset(data)
      var_info(lapply(names(data), function(var) {
        list(
          name = var,
          type = class(data[[var]])[1],
          levels = if(is.factor(data[[var]])) levels(data[[var]]) else NULL
        )
      }))
    }, error = function(e) {
      showNotification(paste("Error reading file:", e$message), type = "error")
    })
  })
  
  observeEvent(input$load_sample, {
    sample_data <- read.csv("https://mathieuferry.github.io/PondicherryWorkshop/material/data/sample.csv")
    var_types <- detect_var_types(sample_data)
    for (col in names(sample_data)) {
      if (var_types[col] == "factor") {
        sample_data[[col]] <- as.factor(sample_data[[col]])
      } else if (var_types[col] == "character") {
        sample_data[[col]] <- as.character(sample_data[[col]])
      }
    }
    dataset(sample_data)
    var_info(lapply(names(sample_data), function(var) {
      list(
        name = var,
        type = class(sample_data[[var]])[1],
        levels = if(is.factor(sample_data[[var]])) levels(sample_data[[var]]) else NULL
      )
    }))
  })
  
  # Data summary
  output$data_summary <- renderText({
    req(dataset())
    data <- dataset()
    paste("Rows:", nrow(data), "\nColumns:", ncol(data))
  })
  
  # Variable management UI ---------------------
  # Function to generate variable management UI
  # Function to generate variable management UI
  generate_var_management_ui <- function() {
    req(var_info())
    lapply(var_info(), function(var) {
      fluidRow(
        column(2, textInput(paste0(var$name, "_name"), "Name", value = var$name)),
        column(2, selectInput(paste0(var$name, "_type"), "Type",
                              choices = c("numeric", "factor", "character"),
                              selected = var$type)),
        column(4, if(var$type == "factor") {
          tagList(
            sortable::sortable_js(paste0(var$name, "_levels")),
            tags$div(id = paste0(var$name, "_levels"),
                     lapply(seq_along(var$levels), function(i) {
                       tags$div(
                         style = "display: flex; align-items: center; margin-bottom: 5px;",
                         tags$span(class = "glyphicon glyphicon-menu-hamburger",
                                   style = "margin-right: 10px; cursor: move;"),
                         textInput(paste0(var$name, "_level_", i),
                                   label = NULL,
                                   value = var$levels[i])
                       )
                     })
            ),
            tags$script(sprintf("
      var sortable_%s = new Sortable(document.getElementById('%s_levels'), {
        onSort: function (evt) {
          var itemElems = evt.from.children;
          var newOrder = Array.prototype.map.call(itemElems, function(itemElem) {
            return itemElem.querySelector('input').value;
          });
          Shiny.setInputValue('%s_level_order', newOrder);
        }
      });
    ", var$name, var$name, var$name)),
            verbatimTextOutput(paste0(var$name, "_debug"))
          )
        } else {
          NULL
        }),
        column(2, checkboxInput(paste0(var$name, "_create_new"), "Create New Column")),
        column(2, actionButton(paste0(var$name, "_apply"), "Apply Changes"))
      )
    })
  }
  
  # Initial render of variable management UI
  output$variable_management <- renderUI({
    generate_var_management_ui()
  })
  
  # Initialize var_info reactiveVal
  var_info <- reactiveVal(list())
  
  # Initialize dataset reactiveVal
  dataset <- reactiveVal(data.frame())
  
  # Function to update var_info
  update_var_info <- function(data) {
    var_info(lapply(names(data), function(v) {
      list(
        name = v,
        type = class(data[[v]])[1],
        levels = if(is.factor(data[[v]])) levels(data[[v]]) else NULL
      )
    }))
  }
  
  # Initialize observers for each variable
  observe({
    data <- dataset()
    lapply(names(data), function(var_name) {
      observeEvent(input[[paste0(var_name, "_apply")]], {
        new_name <- input[[paste0(var_name, "_name")]]
        new_type <- input[[paste0(var_name, "_type")]]
        create_new <- input[[paste0(var_name, "_create_new")]]
        
        current_var <- data[[var_name]]
        
        if (new_type == "numeric") {
          if (is.numeric(current_var)) {
            new_var <- current_var
          } else {
            if (all(!is.na(suppressWarnings(as.numeric(as.character(current_var)))))) {
              new_var <- as.numeric(as.character(current_var))
            } else {
              showNotification("Cannot convert to numeric. Some values are non-numeric.", type = "error")
              return()
            }
          }
        } else if (new_type == "factor") {
          if (is.factor(current_var)) {
            old_levels <- levels(current_var)
            
            # Get the new order of levels from the JavaScript-updated input
            new_levels <- input[[paste0(var_name, "_level_order")]] %||% 
              sapply(seq_along(old_levels), function(i) {
                input[[paste0(var_name, "_level_", i)]]
              })
            
            # Remove any NA or empty values
            new_levels <- new_levels[!is.na(new_levels) & new_levels != ""]
            
            print("Debug: UI Inputs (New Levels Order)")
            print(new_levels)
            
            # Create a mapping from old levels to new levels
            level_map <- setNames(new_levels, old_levels)
            
            # Create a new factor with updated levels and reordered values
            new_var <- factor(level_map[as.character(current_var)], levels = new_levels)
            
            print("Debug: Updated Factor Levels")
            print(levels(new_var))
            
            # Verify the order of unique values in the new factor
            print("Debug: Unique values in new factor")
            print(unique(new_var))
          } else {
            unique_values <- unique(current_var)
            if (length(unique_values) <= 10) {
              new_var <- factor(current_var)
            } else {
              showNotification("Cannot convert to factor. More than 10 unique values.", type = "error")
              return()
            }
          }
        }  else {
          new_var <- as.character(current_var)
        }
        
        if (create_new && new_name != var_name) {
          data[[new_name]] <- new_var
        } else {
          data[[var_name]] <- new_var
          if (new_name != var_name) {
            names(data)[names(data) == var_name] <- new_name
          }
        }
        
        # Update the dataset
        dataset(data)
        
        # Update var_info
        update_var_info(data)
        
        # Force re-render of variable management UI
        output$variable_management <- renderUI({
          generate_var_management_ui()
        })
        
        # Trigger an event to notify other parts of the app that the data has changed
        session$sendCustomMessage(type = 'datasetUpdated', message = list())
        
        showNotification("Variable updated successfully", type = "message")
      })
    })
  })
  
  # React to changes in dataset structure
  observe({
    data <- dataset()
    update_var_info(data)
    
    # Force re-render of variable management UI
    output$variable_management <- renderUI({
      generate_var_management_ui()
    })
  })
  
  # Data view
  output$data_view <- renderDT({
    req(dataset())
    datatable(dataset(), options = list(scrollX = TRUE))
  })
  
  # Download data
  output$downloadData <- downloadHandler(
    filename = function() {
      paste("dataset", switch(input$export_format,
                              csv = ".csv",
                              xls = ".xls",
                              xlsx = ".xlsx",
                              rdata = ".RData",
                              rds = ".rds"), sep = "")
    },
    content = function(file) {
      switch(input$export_format,
             csv = write.csv(dataset(), file, row.names = FALSE),
             xls = write_xlsx(dataset(), file),
             xlsx = write_xlsx(dataset(), file),
             rdata = save(dataset, file = file),
             rds = saveRDS(dataset(), file)
      )
    }
  )
  
  # Univariate analysis ---------------
  output$var_select_uni <- renderUI({
    req(dataset())
    factor_vars <- names(dataset())[sapply(dataset(), is.factor)]
    numeric_vars <- names(dataset())[sapply(dataset(), is.numeric)]
    
    selectInput("var_uni", "Select Variable:", choices = c(factor_vars,numeric_vars))
  })
  
  output$var_calc_uni<-renderUI({
    req(input$var_uni,dataset())
    var_uni<-input$var_uni
    data<-dataset()
    
    if(is.factor(data[[var_uni]])){
      radioButtons("calc_uni","Choice of calculation on plot:",choices=c("Frequency (N)","Proportion (%)"))
    }
  })
  
  output$univariate_table <- renderDT({
    req(input$var_uni)
    var <- input$var_uni
    data<-dataset()
    if(is.numeric(data[[var]])) {
      tab<-as.data.frame(t(summary(data[[var]])))
      tab<- tab %>% mutate(Descriptive=Var2) %>% select(c(Descriptive,Freq))
      datatable(tab)
    } else {
      
      result<- data %>% count(!!sym(var)) %>% mutate(proportion=round(n/sum(n)*100,2))
      # freq_table <- table(var)
      # result <- data.frame(
      #   Category = names(freq_table),
      #   Frequency = as.vector(freq_table),
      #   Percentage = round(100 * prop.table(freq_table), 2)
      # )
      datatable(result)
    }
  })
  
  output$univariate_plot <- renderPlot({
    req(input$var_uni,dataset())
    data<-dataset()
    var <- input$var_uni
    if(is.numeric(data[[var]])) {
      ggplot(dataset(), aes(x=!!sym(var))) + 
        geom_histogram(binwidth=1)+
        labs(title=paste("Histogram of", var),x=var)+
        theme_minimal()+
        theme(axis.text=element_text(size=18),axis.title=element_text(size=18))
      
    } else {
      result<-data %>% count(!!sym(var)) %>% mutate(proportion=round(n/sum(n)*100,2))
      if(input$calc_uni=="Frequency (N)"){
        ggplot(data=result, aes(x=!!sym(var), y=n)) +
          geom_bar(stat="identity")+
          geom_text(aes(label=n), vjust=1.6, color="white", size=6)+
          labs(title=paste("Barplot of", var),x=var)+
          theme_minimal()+
          theme(axis.text=element_text(size=18),axis.title=element_text(size=18))
        
      }
      else{
        ggplot(data=result, aes(x=!!sym(var), y=proportion)) +
          geom_bar(stat="identity")+
          geom_text(aes(label=paste0(round(proportion,1),"%")), vjust=1.6, color="white", size=6)+
          labs(title=paste("Barplot of", var),x=var)+
          theme_minimal()+
          theme(axis.text=element_text(size=18),axis.title=element_text(size=18))
        
      }
    }
  })
  
  
  # Bivariate analysis ---------------
  
  # Bivariate analysis
  output$var_select_bi <- renderUI({
    req(dataset())
    factor_vars <- names(dataset())[sapply(dataset(), is.factor)]
    numeric_vars <- names(dataset())[sapply(dataset(), is.numeric)]
    
    
    selectInput("var_bi", "Select Dependent Variable:", choices = c(factor_vars,numeric_vars))
  })
  
  output$var_select_bi_exp <- renderUI({
    req(dataset())
    factor_vars <- names(dataset())[sapply(dataset(), is.factor)]
    numeric_vars <- names(dataset())[sapply(dataset(), is.numeric)]
    vars<-c(factor_vars,numeric_vars)
    selectInput("var_bi_exp", "Select Explanatory Variable:", choices = c(vars),selected=vars[2])
  })
  
  output$display_option <- renderUI({
    req(input$var_bi, input$var_bi_exp, dataset())
    data <- dataset()
    
    if(is.factor(data[[input$var_bi]])) {
      radioButtons("display_type", "Display:", choices = c("Frequency (N)", "Proportion (%)"))
    }
  })
  
  output$bivariate_table <- renderDT({
    req(input$var_bi, input$var_bi_exp, dataset())
    data <- dataset()
    
    if(!input$var_bi %in% names(data) || !input$var_bi_exp %in% names(data)) {
      return(datatable(data.frame(Error = "One or both selected variables not found in dataset")))
    }
    
    var_bi <- data[[input$var_bi]]
    var_bi_exp <- data[[input$var_bi_exp]]
    
    if(is.numeric(var_bi) && is.factor(var_bi_exp)) {
      result <- data %>%
        group_by(!!sym(input$var_bi_exp)) %>%
        summarise(Mean = round(mean(!!sym(input$var_bi), na.rm = TRUE), 1))
      # Calculate overall mean
      overall_mean <- data %>%
        summarise(Mean = round(mean(!!sym(input$var_bi), na.rm = TRUE), 1)) %>%
        mutate(!!sym(input$var_bi_exp) := "All")
      # Combine group means with overall mean
      result <- bind_rows(result, overall_mean)        
      
    } else if(is.numeric(var_bi) && is.numeric(var_bi_exp)) {
      var_bi_exp_cat <- cut(var_bi_exp, breaks = quantile(var_bi_exp, probs = seq(0, 1, 0.25), na.rm = TRUE), include.lowest = TRUE)
      result <- data %>%
        mutate(Quartile = var_bi_exp_cat) %>%
        group_by(Quartile) %>%
        summarise(Mean = round(mean(!!sym(input$var_bi), na.rm = TRUE),1)) 
      overall_mean <- data %>%
        summarise(Mean = round(mean(!!sym(input$var_bi), na.rm = TRUE), 1)) %>%
        mutate(Quartile = "All")
      result <- bind_rows(result, overall_mean)
      
    } else if(is.factor(var_bi) && is.numeric(var_bi_exp)) {
      var_bi_exp_cat <- cut(var_bi_exp, breaks = quantile(var_bi_exp, probs = seq(0, 1, 0.25), na.rm = TRUE), include.lowest = TRUE)
      data<-data %>%
        mutate(Quartile = var_bi_exp_cat)
      result <- data %>%
        count(Quartile, !!sym(input$var_bi))
      total_row <- result %>%
        group_by(!!sym(input$var_bi)) %>%
        summarise(n = sum(n)) %>%
        mutate(Quartile := "All")
      
      result <- bind_rows(result, total_row) %>%
        group_by(Quartile)
      
      
      
      if(input$display_type == "Proportion (%)") {
        result <- result %>%
          mutate(Value = round(n / sum(n) * 100, 1)) %>%
          select(-n)
      } else {
        result <- result %>%
          rename(Value = n)
      }
      
      result <- result %>%
        pivot_wider(names_from = !!sym(input$var_bi), values_from = Value, values_fill = 0)
      
      # Add total column
      if(input$display_type == "Proportion (%)") {
        result <- result %>%
          mutate(Total = 100)
      } else {
        result <- result %>% ungroup() %>%
          mutate(Total = rowSums(select(., -1)))
      }
      
    }else if(is.factor(var_bi) && is.factor(var_bi_exp)) {
      result <- data %>%
        count(!!sym(input$var_bi_exp), !!sym(input$var_bi))
      total_row <- result %>%
        group_by(!!sym(input$var_bi)) %>%
        summarise(n = sum(n)) %>%
        mutate(!!sym(input$var_bi_exp) := "All")
      
      result <- bind_rows(result, total_row) %>%
        group_by(!!sym(input$var_bi_exp))
      
      
      
      if(input$display_type == "Proportion (%)") {
        result <- result %>%
          mutate(Value = round(n / sum(n) * 100, 1)) %>%
          select(-n)
      } else {
        result <- result %>%
          rename(Value = n)
      }
      
      result <- result %>%
        pivot_wider(names_from = !!sym(input$var_bi), values_from = Value, values_fill = 0)
      
      # Add total column
      if(input$display_type == "Proportion (%)") {
        result <- result %>%
          mutate(Total = 100)
      } else {
        result <- result %>% ungroup() %>%
          mutate(Total = rowSums(select(., -1)))
      }
    } else {
      return(datatable(data.frame(Error = "Invalid combination of variable types")))
    }
    
    # Transpose the result
    # result_t <- data.frame(t(result[-1]))
    # colnames(result_t) <- result[[1]]
    # result_t$Variable <- rownames(result_t)
    # result_t <- result_t %>% select(Variable, everything())
    
    datatable(result)
  })
  
  output$bivariate_plot <- renderPlot({
    req(input$var_bi, input$var_bi_exp, dataset())
    data <- dataset()
    
    if(!input$var_bi %in% names(data) || !input$var_bi_exp %in% names(data)) {
      return(ggplot() + 
               geom_text(aes(x = 0, y = 0, label = "One or both selected variables not found in dataset")) + 
               theme_void())
    }
    
    var_bi <- data[[input$var_bi]]
    var_bi_exp <- data[[input$var_bi_exp]]
    
    if(is.numeric(var_bi) && is.factor(var_bi_exp)) {
      ggplot(data, aes(x = !!sym(input$var_bi_exp), y = !!sym(input$var_bi))) +
        geom_boxplot() +
        labs(x = input$var_bi_exp, y = input$var_bi) +
        theme_minimal()+
        theme(axis.title = element_text(size=18),axis.text = element_text(size=18))
    } else if(is.numeric(var_bi) && is.numeric(var_bi_exp)) {
      ggplot(data, aes(x = !!sym(input$var_bi_exp), y = !!sym(input$var_bi))) +
        geom_point() +
        geom_smooth(method = "lm") +
        labs(x = input$var_bi_exp, y = input$var_bi,caption=paste("Pearson's correlation: ",sprintf('%#.2f',cor(var_bi,var_bi_exp,use="complete.obs")))) +
        theme_minimal()+
        theme(axis.title = element_text(size=18),axis.text = element_text(size=18),plot.caption = element_text(size=18))
      
    } else if(is.factor(var_bi) && is.numeric(var_bi_exp)) {
      
      var_bi_exp_cat <- cut(var_bi_exp, breaks = quantile(var_bi_exp, probs = seq(0, 1, 0.25), na.rm = TRUE), include.lowest = TRUE)
      data<-data %>%
        mutate(Quartile = var_bi_exp_cat)
      plot_data <- data %>%
        count(Quartile, !!sym(input$var_bi)) %>%
        group_by(Quartile) %>%
        mutate(prop = n / sum(n),
               label = sprintf("%.1f%%", prop * 100))
      plot <- ggplot(plot_data, aes(x = Quartile, y = prop, fill = !!sym(input$var_bi)))
      
      if(input$display_type == "Proportion (%)") {
        plot <- plot +
          geom_bar(stat = "identity", position = "fill") +
          geom_text(aes(label = label), position = position_fill(vjust = 0.5), size = 6) +
          scale_y_continuous(labels = scales::percent) +
          labs(x = paste(input$var_bi_exp," (quartile categorization)"), y = "Proportion", fill = input$var_bi)
        
      } else {
        plot <- plot +
          geom_bar(stat = "identity", position = "stack") +
          geom_text(aes(label = n), position = position_stack(vjust = 0.5), size = 6) +
          labs(x = paste(input$var_bi_exp," (quartile categorization)"), y = "Frequency", fill = input$var_bi)
      }
      
      plot + theme_minimal() + scale_fill_brewer(palette="Spectral")+ theme(axis.title = element_text(size=18),axis.text = element_text(size=18))
      
    } else if(is.factor(var_bi) && is.factor(var_bi_exp)) {
      plot_data <- data %>%
        count(!!sym(input$var_bi_exp), !!sym(input$var_bi)) %>%
        group_by(!!sym(input$var_bi_exp)) %>%
        mutate(prop = n / sum(n),
               label = sprintf("%.1f%%", prop * 100))
      plot <- ggplot(plot_data, aes(x = !!sym(input$var_bi_exp), y = prop, fill = !!sym(input$var_bi)))
      
      if(input$display_type == "Proportion (%)") {
        plot <- plot +
          geom_bar(stat = "identity", position = "fill") +
          geom_text(aes(label = label), position = position_fill(vjust = 0.5), size = 6) +
          scale_y_continuous(labels = scales::percent) +
          labs(x = input$var_bi_exp, y = "Proportion", fill = input$var_bi)
      } else {
        plot <- plot +
          geom_bar(stat = "identity", position = "stack") +
          geom_text(aes(label = n), position = position_stack(vjust = 0.5), size = 6) +
          labs(x = input$var_bi_exp, y = "Frequency", fill = input$var_bi)
      }
      
      plot + theme_minimal()+ scale_fill_brewer(palette="Spectral")+ theme(axis.title = element_text(size=18),axis.text = element_text(size=18))
    } else {
      ggplot() + 
        geom_text(aes(x = 0, y = 0, label = "Invalid combination of variable types")) + 
        theme_void()
    }
  })  
  # Textual analysis -----------------
  output$text_var_select <- renderUI({
    req(dataset())
    char_vars <- names(dataset())[sapply(dataset(), is.character)]
    selectInput("text_var", "Select Text Variable:", choices = char_vars)
  })
  
  output$text_cleaning_options <- renderUI({
    req(dataset())
    tagList(
      checkboxInput("remove_punct", "Remove Punctuation", value = TRUE),
      checkboxInput("remove_numbers", "Remove Numbers", value = TRUE),
      checkboxInput("remove_symbols", "Remove Symbols", value = TRUE),
      checkboxInput("to_lower", "Convert to Lowercase", value = TRUE),
      checkboxInput("remove_stopwords", "Remove Stopwords", value = TRUE),
      conditionalPanel(
        condition = "input.remove_stopwords == true",
        selectInput("stopwords_lang", "Stopwords Language:",
                    choices = c("english", "french", "german", "spanish", "italian"),
                    selected = "english")
      ),
      checkboxInput("remove_manualpwords", "Remove words manually from corpus", value = F),
      conditionalPanel(
        condition = "input.remove_manualpwords == true",
        textInput("words_to_rm", "Words to remove (separated by commas):")
      ),
      checkboxInput("detailedlangcleaning","Detailed language cleaning (takes more time to run!)",value=F),
      conditionalPanel(
        condition="input.detailedlangcleaning==true",
        selectInput("langcleaning",HTML("<a href='https://universaldependencies.org/'>Language</a> of text to analyse"),
                    choices=c("afrikaans-afribooms", "ancient_greek-perseus", "ancient_greek-proiel",
                              "arabic-padt", "armenian-armtdp", "basque-bdt", "belarusian-hse", "bulgarian-btb",
                              "buryat-bdt", "catalan-ancora", "chinese-gsd", "chinese-gsdsimp",
                              "classical_chinese-kyoto", "coptic-scriptorium", "croatian-set", "czech-cac",
                              "czech-cltt", "czech-fictree", "czech-pdt", "danish-ddt", "dutch-alpino",
                              "dutch-lassysmall", "english-ewt", "english-gum", "english-lines", "english-partut",
                              "estonian-edt", "estonian-ewt", "finnish-ftb",      "finnish-tdt", "french-gsd",
                              "french-partut", "french-sequoia", "french-spoken", "galician-ctg",
                              "galician-treegal", "german-gsd", "german-hdt", "gothic-proiel", "greek-gdt",
                              "hebrew-htb", "hindi-hdtb", "hungarian-szeged", "indonesian-gsd", "irish-idt",
                              "italian-isdt", "italian-partut", "italian-postwita", "italian-twittiro",
                              "italian-vit", "japanese-gsd", "kazakh-ktb", "korean-gsd", "korean-kaist",
                              "kurmanji-mg", "latin-ittb", "latin-perseus", "latin-proiel", "latvian-lvtb",
                              "lithuanian-alksnis",      "lithuanian-hse", "maltese-mudt", "marathi-ufal",
                              "north_sami-giella", "norwegian-bokmaal", "norwegian-nynorsk",
                              "norwegian-nynorsklia", "old_church_slavonic-proiel", "old_french-srcmf",
                              "old_russian-torot", "persian-seraji", "polish-lfg", "polish-pdb", "polish-sz",
                              "portuguese-bosque", "portuguese-br", "portuguese-gsd", "romanian-nonstandard",
                              "romanian-rrt", "russian-gsd", "russian-syntagrus", "russian-taiga", "sanskrit-ufal",
                              "scottish_gaelic-arcosg", "serbian-set", "slovak-snk", "slovenian-ssj",     
                              "slovenian-sst", "spanish-ancora", "spanish-gsd", "swedish-lines",
                              "swedish-talbanken", "tamil-ttb", "telugu-mtg", "turkish-imst", "ukrainian-iu",
                              "upper_sorbian-ufal", "urdu-udtb", "uyghur-udt", "vietnamese-vtb", "wolof-wtb"),selected="english-ewt"),
        checkboxInput("select_wordforms",HTML("Select <a href='https://universaldependencies.org/u/pos/index.html'>word forms</a> to analyze"),value=F),
        conditionalPanel(
          condition="input.select_wordforms==true",
          selectInput("forms_keep","Choose from available options",
                      c("ADJ",
                        "ADP",
                        "ADV",
                        "AUX",
                        "CCONJ",
                        "DET",
                        "INTJ",
                        "NOUN",
                        "NUM",
                        "PART",
                        "PRON",
                        "PROPN",
                        "PUNCT",
                        "SCONJ",
                        "SYM",
                        "VERB",
                        "X"),multiple=TRUE)
        ),
        checkboxInput("lemmatize","Lemmatize corpus",value=F)
      ),
      
      sliderInput("minwordsize", "Minimum number of character for a word", min = 1, max = 10, value = 3),
      sliderInput("minwordsmention", "Minimum number of occurrences of words in whole corpus", min = 1, max = 100, value = 10),
      sliderInput("minwordsegment", "Number of words per segment (~ paragraphs, if possible determined by dots and commas)", min = 10, max = 500, value = 40)
      
    )
  })
  
  # observeEvent(input$clean_text, {
  #   req(input$langcleaning)
  #   udpipe_download_model(language = input$langcleaning)
  #   udmodel<-udpipe_load_model(file = list.files(pattern='english'))
  # })
  
  
  ##We also need corpus without transformation
  corpnotransf<-  eventReactive(input$clean_text,{
    text_var <- dataset()[[input$text_var]]
    corp <- corpus(text_var)
    corp
  })
  
  corpnotransfsplit<-  eventReactive(input$clean_text,{
    req(corpnotransf())
    corpsplit <- split_segments(corpnotransf(), segment_size = input$minwordsegment)
    corpsplit
  })
  
  ##Here, corpus with transformation... 
  
  corp <- eventReactive(input$clean_text, {
    withProgress(message = 'Processing text...', value = 0, {
      text_var <- dataset()[[input$text_var]]
      
      if(input$detailedlangcleaning) {
        incProgress(0.1, detail = "Downloading language model...")
        udmodel <- udpipe_download_model(language = input$langcleaning)
        
        if(input$select_wordforms & !input$lemmatize) {
          req(input$forms_keep)
          forms <- input$forms_keep
          getforms <- function(x) {
            ttg <- udpipe(x, object = udmodel)
            ttg <- ttg[ttg$upos %in% forms,]
            return(paste(ttg$token, collapse=" "))
          }
          incProgress(0.3, detail = "Processing word forms...")
          text_var <- unlist(lapply(seq_along(text_var), function(i) {
            incProgress(0.5 / length(text_var), detail = sprintf("Processing text %d of %d", i, length(text_var)))
            getforms(text_var[i])
          }))
        } else if(input$select_wordforms & input$lemmatize) {
          req(input$forms_keep)
          forms <- input$forms_keep
          getforms <- function(x) {
            ttg <- udpipe(x, object = udmodel)
            ttg <- ttg[ttg$upos %in% forms,]
            return(paste(ttg$lemma, collapse=" "))
          }
          incProgress(0.3, detail = "Processing word forms and lemmatizing...")
          text_var <- unlist(lapply(seq_along(text_var), function(i) {
            incProgress(0.5 / length(text_var), detail = sprintf("Processing text %d of %d", i, length(text_var)))
            getforms(text_var[i])
          }))
        } else if(!input$select_wordforms & input$lemmatize) {
          getforms <- function(x) {
            ttg <- udpipe(x, object = udmodel)
            return(paste(ttg$lemma, collapse=" "))
          }
          incProgress(0.3, detail = "Lemmatizing...")
          text_var <- unlist(lapply(seq_along(text_var), function(i) {
            incProgress(0.5 / length(text_var), detail = sprintf("Processing text %d of %d", i, length(text_var)))
            getforms(text_var[i])
          }))
        }
      }
      
      incProgress(0.9, detail = "Creating corpus...")
      # Transform to corpus
      corp <- corpus(text_var)
      
      incProgress(1, detail = "Done!")
      corp
    })
  })
  
  dtm<- eventReactive(input$clean_text, {
    req(corp())
    
    
    # Tokenize the text
    tokenc <- tokens(corp())
    
    
    # Apply selected cleaning options
    if(input$remove_punct) tokenc <- tokens(tokenc, remove_punct = TRUE) %>% as.tokens()
    if(input$remove_numbers) tokenc <- tokens(tokenc, remove_numbers = TRUE) %>% as.tokens()
    if(input$remove_symbols) tokenc <- tokens(tokenc, remove_symbols = TRUE) %>% as.tokens()
    if(input$to_lower) tokenc <- tokens_tolower(tokenc)
    if(input$remove_stopwords) {
      tokenc <- tokens_remove(tokenc, stopwords(input$stopwords_lang))
    }
    if(input$remove_manualpwords & input$words_to_rm!="") {
      man_torm<-trimws(unlist(strsplit(input$words_to_rm,",")))
      tokenc <- tokens_remove(tokenc, man_torm)
    }
    
    
    tokenc<-tokens_select(tokenc,min_nchar=input$minwordsize)
    dtm <- dfm(tokenc, tolower = T)
    dtm <- dfm_trim(dtm, min_docfreq = input$minwordsmention)
    dtm
  })
  
  
  corpsplit<-  eventReactive(input$clean_text,{
    req(corp())
    corpsplit <- split_segments(corp(), segment_size = input$minwordsegment)
    corpsplit
  })
  
  
  
  dtmsplit<- eventReactive(input$clean_text, {
    req(corpsplit())
    
    
    
    
    # Tokenize the text
    tokenc <- tokens(corpsplit())
    
    # Apply selected cleaning options
    if(input$remove_punct) tokenc <- tokens(tokenc, remove_punct = TRUE) %>% as.tokens()
    if(input$remove_numbers) tokenc <- tokens(tokenc, remove_numbers = TRUE) %>% as.tokens()
    if(input$remove_symbols) tokenc <- tokens(tokenc, remove_symbols = TRUE) %>% as.tokens()
    if(input$to_lower) tokenc <- tokens_tolower(tokenc)
    if(input$remove_stopwords) {
      tokenc <- tokens_remove(tokenc, stopwords(input$stopwords_lang))
    }
    if(input$remove_manualpwords & input$words_to_rm!="") {
      man_torm<-trimws(unlist(strsplit(input$words_to_rm,",")))
      tokenc <- tokens_remove(tokenc, man_torm)
    }
    
    tokenc<-tokens_select(tokenc,min_nchar=input$minwordsize)
    dtm <- dfm(tokenc, tolower = T)
    dtm <- dfm_trim(dtm, min_docfreq = input$minwordsmention)
    dtm
    #showNotification("Text cleaned successfully and transformed to a document-feature matrix.", type = "message")
  })
  
  output$corpus_summary <- renderText({
    req(corp(),corpsplit())
    corpsum<-quanteda.textstats::textstat_summary(corp())
    corpsumnonempty<-corpsum %>% filter(tokens>0)
    nseg<-nrow(docvars(corpsplit()))
    #head(docvars(corpsplit()))
    paste("Number of non-empty documents:", nrow(corpsumnonempty),
          "\nNumber of segments:", nseg,
          "\nAverage number of segments per non-empty document:", nseg/nrow(corpsumnonempty),
          "\nAverage number of words (tokens) per non-empty document:", round(mean(corpsumnonempty$tokens,na.rm=T),0))
  })
  
  
  output$freq_terms_table <- renderDT({
    req(dtm())
    freq <- textstat_frequency(dtm()) %>% select(-group)
    datatable(freq,caption="Frequency is the count of the feature (word) in the whole corpus.\n
             Rank is the rank of the frequency (1 is the greatest frequency).\n
             Docfreq is the document frequency (the number of documents in which this feature occurred at least once).")
  })
  
  
  output$wordcloud <- renderPlot({
    req(dtm())
    textplot_wordcloud(dtm(), random_order = F, rotation = 0.25,min_size =1,max_words = input$maxwords,
                       color = RColorBrewer::brewer.pal(8, "Dark2"))
    
  },width=500,height=500)
  
  # madfm <- dfm_group(dtm, groups=sample_data$Sex)
  
  # Stratified freq server -------------------
  
  observe({
    req(dataset())
    print("dataset() output:")
    print(dataset())
    
    # Ensure dataset has columns and handle the case when it's empty
    if (ncol(dataset()) > 0) {
      updateSelectInput(session, "strat_var_forfreq", 
                        choices = names(dataset())[sapply(dataset(), function(x) is.factor(x) | is.numeric(x))])
    } else {
      updateSelectInput(session, "strat_var_forfreq", choices = NULL)
    }
  })
  
  
  observe({
    req(dtm())
    print("dtm() output:")
    print(dtm())
    
    word_choices <- sort(colnames(dtm()))
    updateSelectInput(session, "word_choice_forfreq", 
                      choices = word_choices)
  })
  

  stratified_frequency <- eventReactive(input$compute_strat_freq, {
    req(dataset(), dtm(), input$strat_var_forfreq, input$word_choice_forfreq)
    
    # Get the stratification variable
    strat_var <- dataset()[[input$strat_var_forfreq]]
    
    # If numeric, categorize into quartiles
    if(is.numeric(strat_var)) {
      strat_var <- cut(strat_var, breaks = quantile(strat_var, probs = 0:4/4, na.rm = TRUE), 
                       include.lowest = TRUE, labels = c("Q1", "Q2", "Q3", "Q4"))
    }
    
    dtm_df <- convert(dtm(),to="data.frame")
    dtm_df$strat_var <- strat_var
    
    # Compute stratified frequency
    result <- dtm_df %>%
      group_by(strat_var) %>%
      summarise(
        occurrences = sum(!!sym(input$word_choice_forfreq), na.rm = TRUE),
        total_words = sum(across(where(is.numeric), \(x) sum(x, na.rm = TRUE))),
        documents_with_word = sum(!!sym(input$word_choice_forfreq) > 0, na.rm = TRUE),
        total_documents = n()
      ) %>%
      mutate(
        proportion_occurrences = occurrences / total_words * 100,
        proportion_documents = documents_with_word / total_documents * 100
      ) %>% select(strat_var,occurrences,proportion_occurrences,documents_with_word,proportion_documents)
    
    return(result)
  })
  
  output$strat_freq_table <- renderDT({
    req(stratified_frequency())
    datatable(stratified_frequency(), 
              caption = paste("Stratified occurrence for word:", input$word_choice_forfreq,"by :",input$strat_var_forfreq)) %>%
    formatRound(columns = c("proportion_occurrences", "proportion_documents"), digits = 1)
  
  })
  
  
  # Context server -----------------
  output$word_to_search <- renderUI({
    req(dataset())
    textInput("word_input", "Search textual context of a word:")
  })
  
  observeEvent(input$search_context, {
    req(corpnotransf(), input$word_input)
    
    output$table_context <- renderDT({
      cont <- kwic(tokens(corpnotransf()), pattern = input$word_input, window = 5)
      contsum<-cont #%>% select(docname,pre,keyword,post)
      # Convert the kwic object to a data frame
      # cont_df <- data.frame(
      #   pre = sapply(cont$pre, paste, collapse = " "),
      #   keyword = cont$keyword,
      #   post = sapply(cont$post, paste, collapse = " "),
      #   stringsAsFactors = FALSE
      # )
      
      # Return the data frame
      contsum
    })
  })
  
  
  
  
  # Dual wordcloud -----------------
  output$wordcloud_var_select <- renderUI({
    req(dataset())
    factor_vars <- names(dataset())[sapply(dataset(), is.factor)]
    selectInput("wordcloud_var", "Select factor variable for word cloud:",
                choices = factor_vars,
                selected = factor_vars[1])
  })
  
  output$factor_level_select <- renderUI({
    req(input$wordcloud_var)
    levels <- levels(dataset()[[input$wordcloud_var]])
    tagList(
      selectInput("level1", "Select first level:", choices = levels),
      selectInput("level2", "Select second level:", choices = levels)
    )
  })
  
  
  
  observeEvent(input$confirm, {
    req(input$wordcloud_var, input$level1, input$level2)
    
    selected_var <- input$wordcloud_var_select
    
    #levels <- unique(dataset()[[selected_var]])
    
    if (input$level1 != input$level2) {
      showNotification(paste("You have selected levels:", input$level1, "and", input$level2), type = "message")
    } else {
      showNotification("Please select two different levels.", type = "error")
    }
  })
  
  
  output$dualwordcloud_plot <- renderPlot({
    req(input$confirm, input$wordcloud_var, input$level1, input$level2)
    dtm<-dtm()
    data<-dataset()
    selected_var <- input$wordcloud_var
    level1<-input$level1
    level2<-input$level2
    
    
    dtm <- dfm_group(dtm, groups=data[[selected_var]])
    dtm <- dfm_subset(dtm, docnames(dtm) %in%  c(level1,level2))
    
    textplot_wordcloud(dtm, comparison = TRUE,max_words = input$maxdualwords,color = c("darkgreen", "darkorange"))
  })
  
  
  
  output$dualfreq_terms_tableTop <- renderDT({
    
    req(input$confirm, input$wordcloud_var, input$level1, input$level2)
    dtm<-dtm()
    data<-dataset()
    selected_var <- input$wordcloud_var
    level1<-input$level1
    level2<-input$level2
    dtm <- dfm_group(dtm, groups=data[[selected_var]])
    dtm <- dfm_subset(dtm, docnames(dtm) %in%  c(level1,level2))
    tab<-head(textstat_keyness(dtm), input$maxkeyness)
    datatable(tab,caption=paste0("Most characteristics features of ",input$level1)) %>% formatRound(c(2,3),2)
    
  })
  output$dualfreq_terms_tableBttm <- renderDT({
    req(input$confirm, input$wordcloud_var, input$level1, input$level2)
    dtm<-dtm()
    data<-dataset()
    selected_var <- input$wordcloud_var
    level1<-input$level1
    level2<-input$level2
    dtm <- dfm_group(dtm, groups=data[[selected_var]])
    dtm <- dfm_subset(dtm, docnames(dtm) %in%  c(level1,level2))
    tab<-tail(textstat_keyness(dtm), input$maxkeyness) %>% arrange(chi2) 
    datatable(tab,caption=paste0("Most characteristics features of ",input$level2)) %>% formatRound(c(2,3),2)
  })
  
  
  # Cooccurrences server side -----------------
  
  
  output$what_to_coocc <- renderUI({
    req(dataset())
    factor_vars <- names(dataset())[sapply(dataset(), is.factor)]
    
    
    tagList(
      radioButtons("what_coocc","Type of co-occurrences",choices=c("Co-occurrences between 50 most frequent features","Co-occurrences of a word")),
      conditionalPanel(
        condition="input.what_coocc == 'Co-occurrences of a word'",
        textInput("word_coocc","Write word:")
      ),
      radioButtons("where_coocc","Which section of the corpus?",choices=c("The entire corpus","Filtered corpus")),
      conditionalPanel(
        condition="input.where_coocc == 'Filtered corpus'",
        selectInput("coocc_varfilter", "Select factor variable to filter corpus:",
                    choices = factor_vars,
                    selected = factor_vars[1])
      )
    )
    
  })
  
  output$level_toocc <- renderUI({
    req(dataset(),input$where_coocc == "Filtered corpus",input$coocc_varfilter)
    levels <- levels(dataset()[[input$coocc_varfilter]])
    
    tagList(
      conditionalPanel(
        condition="input.where_coocc == 'Filtered corpus'",
        selectInput("coocc_levelfilter", "Select level of variable:",
                    choices = levels,
                    selected = levels[1])
      )
      
    )
    
  })
  
  observeEvent(input$display_coocc, {
    req(input$what_coocc, input$where_coocc)
    
    if (input$what_coocc=="Co-occurrences between 50 most frequent features" & input$where_coocc=="The entire corpus") {
      showNotification("Most frequent co-occurrences within segments of words on the entire corpus",type = "message")
    } else if(input$what_coocc=="Co-occurrences between 50 most frequent features" & input$where_coocc=="Filtered corpus"){
      showNotification(paste0("Most frequent co-occurrences within segments of words on the corpus of ",input$coocc_levelfilter),type = "message")
    } else if(input$what_coocc=="Co-occurrences of a word" & input$word_coocc!="" & input$where_coocc=="Filtered corpus"){
      showNotification(paste0("Co-occurrences of ",input$word_coocc," within segments of words on the corpus of ",input$coocc_levelfilter),type = "message")
    } else if(input$what_coocc=="Co-occurrences of a word" & input$where_coocc=="The entire corpus"){
      showNotification(paste0("Co-occurrences of ",input$word_coocc," within segments of words on the entire corpus"),type = "message")
    } else{
      showNotification("Select options!",type = "error")
      
    }
  })
  
  
  output$plot_coocc <- renderPlot({
    req(input$display_coocc, input$what_coocc, input$where_coocc,dataset(), dtmsplit())
    dtmsplit<-dtmsplit()
    data <- dataset()
    
    
    if (input$what_coocc=="Co-occurrences between 50 most frequent features" & input$where_coocc=="The entire corpus") {
      
      featsplit <- names(topfeatures(dtmsplit, 50))
      
      fcm<- fcm(dtmsplit, context="document")
      fcm_selected <- fcm_select(fcm, pattern = featsplit, selection = "keep")
      textplot_network(fcm_selected)
      
      
    } else if(input$what_coocc=="Co-occurrences between 50 most frequent features" & input$where_coocc=="Filtered corpus"){
      req(input$coocc_varfilter, input$coocc_levelfilter)
      
      nsegments<-data.frame(table(sub("\\_.*", "", dtmsplit@docvars$docname_)))
      
      #nsegments<-docvars(dtmsplit) %>% count(segment_source)
      namevarfilt<-input$coocc_varfilter
      namelevelfilt<-input$coocc_levelfilter
      vartofilt<-rep(data[[namevarfilt]],times=nsegments$Freq)
      dtmsplit <- dfm_group(dtmsplit, groups=vartofilt)
      dtmsplit <- dfm_subset(dtmsplit, docnames(dtmsplit) %in%  c(namelevelfilt))
      featsplit <- names(topfeatures(dtmsplit, 50))
      
      fcm<- fcm(dtmsplit, context="document")
      fcm_selected <- fcm_select(fcm, pattern = featsplit, selection = "keep")
      textplot_network(fcm_selected)
      
      
    } else if(input$what_coocc=="Co-occurrences of a word" & input$word_coocc!="" & input$where_coocc=="Filtered corpus"){
      req(input$word_coocc)
      feat<-input$word_coocc
      nsegments<-data.frame(table(sub("\\_.*", "", dtmsplit@docvars$docname_)))
      
      #nsegments<-docvars(dtmsplit) %>% count(segment_source)
      namevarfilt<-input$coocc_varfilter
      namelevelfilt<-input$coocc_levelfilter
      vartofilt<-rep(data[[namevarfilt]],times=nsegments$Freq)
      dtmsplit <- dfm_group(dtmsplit, groups=vartofilt)
      dtmsplit <- dfm_subset(dtmsplit, docnames(dtmsplit) %in%  c(namelevelfilt))
      
      fcm<- fcm(dtmsplit, context="document")
      mfcm<-as.matrix(fcm)
      
      tryCatch({
        cooccurf<-data.frame(n=mfcm[feat,]) %>% arrange(-n) %>% top_n(50)%>% filter(n>0) %>% rownames_to_column(var = "feature")
        
        p<-ggplot(data=cooccurf, aes(x=reorder(feature, n), y=n)) +
          geom_bar(stat="identity")+
          geom_text(aes(label=n), vjust=0.5,hjust=1.2 ,color="white", size=4.5)+
          coord_flip()+
          labs(y="Number of co-occurrences\nin segments",x=paste0("Most frequent words\nco-occurring with ",feat))+
          theme_minimal()+
          theme(axis.text=element_text(size=15),axis.title = element_text(size=15))
        p
      },error = function(e) {
        showNotification(paste("Error reading file:", e$message), type = "error")
      })
      
      
      
    } else if(input$what_coocc=="Co-occurrences of a word" & input$where_coocc=="The entire corpus"){
      
      req(input$word_coocc)
      feat<-input$word_coocc
      
      
      fcm<- fcm(dtmsplit, context="document")
      mfcm<-as.matrix(fcm)
      
      tryCatch({
        cooccurf<-data.frame(n=mfcm[feat,]) %>% arrange(-n) %>% top_n(50)%>% filter(n>0) %>% rownames_to_column(var = "feature")
        
        p<-ggplot(data=cooccurf, aes(x=reorder(feature, n), y=n)) +
          geom_bar(stat="identity")+
          geom_text(aes(label=n), vjust=0.5,hjust=1.2 ,color="white", size=4.5)+
          coord_flip()+
          labs(y="Number of co-occurrences\nin segments",x=paste0("Most frequent words\nco-occurring with ",feat))+
          theme_minimal()+
          theme(axis.text=element_text(size=15),axis.title = element_text(size=15))
        p
      },error = function(e) {
        showNotification(paste("Error reading file:", e$message), type = "error")
      })
      
      
    } 
    
  })
  
  
  
  
  # Reinert's algorithm -----------------
  
  
  
  clust<-  eventReactive(input$classify, {
    if(input$whatclass=="Documents"){
      dtm<-dtm()
      result<-rainette(dtm, k = input$maxk)
    }
    else if(input$whatclass=="Segments") {
      dtm<-dtmsplit()
      if(input$howclass=="Simple Descendant Hierarchical Classification"){
        result <- rainette(dtm, k = input$maxk,min_segment_size=input$minseg_simple)
      }
      else if(input$howclass=="Dual Descendant Hierarchical Classification"){
        result1 <- rainette(dtm, k = input$maxk,min_segment_size=input$minseg_dual1)
        #result1 <- rainette(dtm, k = 4,min_segment_size=10)
        
        result2 <- rainette(dtm, k = input$maxk,min_segment_size=input$minseg_dual2)
        #result2 <- rainette(dtm, k = 4,min_segment_size=15)
        
        result <- rainette2(result1, result2, max_k = input$maxk,full = TRUE,parallel = TRUE)
        #result <- rainette2(result1, result2, max_k = 4,full = TRUE,parallel = TRUE)
        
      }
    }
    
    result
  })
  
  
  output$dendrogram <- renderPlot({
    req(clust())
    if(input$whatclass=="Documents"){
      rainette_plot(clust(), dtm(), k = input$maxk, type = "bar", n_terms = input$maxfeatshow, free_scales = FALSE,
                    measure = "chi2", show_negative = "TRUE", text_size = 11)
    }
    else if(input$whatclass=="Segments"){
      if(input$howclass=="Simple Descendant Hierarchical Classification"){
        rainette_plot(clust(), dtmsplit(), k = input$maxk, type = "bar", n_terms = input$maxfeatshow, free_scales = FALSE,
                      measure = "chi2", show_negative = "TRUE", text_size = 11)
      }else if(input$howclass=="Dual Descendant Hierarchical Classification"){
        rainette2_plot(clust(), dtmsplit(), k = input$maxk, type = "bar", n_terms = input$maxfeatshow, free_scales = FALSE,
                       measure = "chi2", show_negative = "TRUE", text_size = 11)
        
      }
    }
    
  })
  
  output$class_selector <- renderUI({
    req(clust())
    classes <- 1:input$maxk
    selectInput("selected_class", "Select Class:", choices = classes)
  })
  
  
  # observe({
  #   table_data <- isolate({
  #     req(clust(), input$selected_class)
  #     class_assignments <- cutree_rainette(clust(), k = input$maxk)
  #     docs <- which(class_assignments == as.integer(input$selected_class))
  #     texts <- data.frame(
  #       doc_id = docs,
  #       content = as.character(corp()[docs])
  #     )
  #     texts
  #   })
  #   print("Table data:")
  #   print(table_data)
  # })
  
  output$document_table <- renderTable({
    req(clust(), input$selected_class)
    
    tryCatch({
      
      if(input$howclass=="Simple Descendant Hierarchical Classification"){
        class_assignments <- cutree_rainette(clust(), k = input$maxk)
      }else if(input$howclass=="Dual Descendant Hierarchical Classification"){
        class_assignments <- cutree_rainette2(clust(), k = input$maxk)
        
      }
      
      docs <- which(class_assignments == as.integer(input$selected_class))
      
      if(input$whatclass == "Documents") {
        texts <- data.frame(
          Document_id = docs,
          Content = as.character(corpnotransf()[docs])
        )
      } else if(input$whatclass == "Segments") {
        segment_ids <- docs
        segment_sources <- docvars(corpnotransfsplit())$segment_source[docs]
        contents <- as.character(corpnotransfsplit()[docs])
        
        texts <- data.frame(
          Document_id = sub('text','',segment_sources),
          Segment_id = segment_ids,
          
          Content = contents
        )
      }
      
      search_word <- input$search_word
      
      if(nchar(search_word) > 0 && !is.null(texts$content)) {
        texts <- texts[grep(search_word, texts$content, ignore.case = TRUE), ]
      }
      
      if(nrow(texts) > 0) {
        texts
      } else {
        data.frame(message = "No documents/segments found matching the criteria")
      }
    }, error = function(e) {
      data.frame(error = paste("An error occurred:", e$message))
    })
  }, sanitize.text.function = function(x) x)
  
  # Add cluster variable(s) --------------------
  
  # Add classification result as new variable
  observeEvent(input$add_var, {
    req(clust(), dataset())
    data <- dataset()
    new_var_name <- input$new_var_name_class
    corpsplit <- corpsplit()
    
    print(paste("whatclass:", input$whatclass))
    print(paste("new_var_name:", new_var_name))
    print(paste("maxk:", input$maxk))
    
    if (is.null(input$whatclass) || input$whatclass == "") {
      showNotification("Please select a valid class type.", type = "error")
      return()
    }
    
    if (input$whatclass == "Documents") {
      if (new_var_name=="") {
        showNotification(paste("Write a variable name to add to dataset!"), type = "message")
      }else if(new_var_name %in% names(data)) {
        showNotification(paste("Variable", new_var_name, "already exists! Pick another name."), type = "message")
      } else {
        clusters <- cutree(clust(), k = input$maxk)
        data[[new_var_name]]<-factor(clusters)
        showNotification("Cluster variable added to dataset (check 'Data Management' tab).", type = "message")
        dataset(data)
        
      }
    } else if (input$whatclass == "Segments") {
      if (is.null(input$maxk) || input$maxk <= 0) {
        showNotification("Please enter a valid number of clusters.", type = "error")
        return()
      }
      
      new_var_names <- paste(new_var_name, seq(1, input$maxk, 1), sep = "_")
      new_var_names <- c(new_var_names, paste(new_var_name, "NA", sep = "_"))
      
      if (is.null(new_var_name) || new_var_name == "") {
        showNotification("Write a variable name prefix to add to dataset!", type = "message")
      } else if (new_var_name[1] %in% names(data)) {
        showNotification(paste("Variable", new_var_name, "already exists! Pick another name."), type = "message")
      } else {
        tryCatch({
          print("Debug: Before cutree")
          print(str(clust()))
          corpsplit$groupe <- cutree(clust(), k = input$maxk)
          print("Debug: After cutree")
          print(str(corpsplit$groupe))
          
          print("Debug: Before clusters_by_doc_table")
          distrib <- clusters_by_doc_table(corpsplit, clust_var = "groupe", prop = TRUE)
          print("Debug: After clusters_by_doc_table")
          print(str(distrib))
          
          lastcol <- input$maxk + 2
          colnames(distrib)[2:lastcol] <- new_var_names
          
          for (i in 2:lastcol) { 
            print(paste("Debug: Processing column", i))
            print(str(distrib[,i]))
            data[[new_var_names[i-1]]] <- as.numeric(distrib[[i]])
          }
          showNotification("Cluster variables added to dataset (check 'Data Management' tab).", type = "message")
          dataset(data)
        }, error = function(e) {
          print(paste("Error:", e$message))
          print("Error details:")
          print(str(e))
          showNotification(paste("Error adding cluster variables:", e$message), type = "error")
        })
      }
    } else {
      showNotification("Invalid class type selected.", type = "error")
    }
  })  
  # AFC on results of classification ------------------
  
  output$correspondance_selector <- renderUI({
    req(clust())
    
    maxaxes<-input$maxk-1
    tagList(
      
      selectInput("axis_horizontal", "Select horizontal axis:", choices = c(1:maxaxes)),
      selectInput("axis_vertical", "Select vertical axis:", choices = c(1:maxaxes),selected=2),
      numericInput("maxfeatafc", "Max number of terms to display by cluster:", 10, min = 1, max = 100)
    )
  })
  
  
  output$AFC <- renderPlot({
    req(clust(), dtm(), input$maxfeatafc, input$axis_horizontal, input$axis_vertical)
    
    clustmemb <- cutree(clust(), k = input$maxk)
    
    if(input$whatclass=="Documents"){
      
      keyterms <- rainette_stats(clustmemb, dtm(), n_terms = input$maxfeatafc, show_negative = FALSE)
      keytermsdat <- do.call(rbind, mapply(transform, keyterms, ID = seq_along(keyterms), SIMPLIFY = FALSE))
      dtmclust <- dfm_group(dtm(), groups = clustmemb)
    }
    else {
      keyterms <- rainette_stats(clustmemb, dtmsplit(), n_terms = input$maxfeatafc, show_negative = FALSE)
      keytermsdat <- do.call(rbind, mapply(transform, keyterms, ID = seq_along(keyterms), SIMPLIFY = FALSE))
      dtmclust <- dfm_group(dtmsplit(), groups = clustmemb)
      
    }
    dtmdat <- cbind(convert(dtmclust, to = "data.frame"), docvars(dtmclust)) %>% column_to_rownames("doc_id")
    
    dtmdatsel <- dtmdat %>% select(all_of(keytermsdat$feature))
    
    ca <- CA(dtmdatsel, graph = FALSE)
    
    coord <- data.frame(ca$col$coord) %>% rownames_to_column("feature")
    coord <- coord %>% left_join(keytermsdat, by = "feature")
    
    Dimh <- paste0("Dim.", input$axis_horizontal)
    Dimv <- paste0("Dim.", input$axis_vertical)
    
    eigh_row <- paste0("dim ", input$axis_horizontal)
    eigv_row <- paste0("dim ", input$axis_vertical)
    
    eigh <- sprintf("%0.1f", ca$eig[eigh_row, "percentage of variance"])
    eigv <- sprintf("%0.1f", ca$eig[eigv_row, "percentage of variance"])
    
    # Ensure ID is a factor
    coord$ID <- as.factor(coord$ID)
    
    ggplot(data = coord, aes(x = !!sym(Dimh), y = !!sym(Dimv))) +
      geom_hline(yintercept = 0, linetype = "dashed") +
      geom_vline(xintercept = 0, linetype = "dashed") +
      geom_point(color="white", size = 1) +  # Add points with color aesthetic
      geom_text_repel(
        aes(label = feature, color = ID, 
            size = pmax(chi2, 10)),  # Set a minimum size threshold
        max.overlaps = Inf,
        show.legend = c(size = FALSE)  # Remove size legend
      ) +
      scale_size_continuous(range = c(4, 10)) +  # Adjust the size range as needed
      scale_color_manual(values = paletteer_d("ggthemes::Tableau_10")) +
      labs(x = paste("Dimension", input$axis_horizontal, "(", eigh, "%)"),
           y = paste("Dimension", input$axis_vertical, "(", eigv, "%)"),
           color = "Cluster") +
      theme_minimal() +
      theme(legend.position = "bottom",axis.title = element_text(size=18),axis.text = element_text(size=15),
            legend.title=element_text(size=18),legend.text = element_text(size=18)) +
      guides(colour = guide_legend(override.aes = list(size=8)))
  }, width = 800, height = 800)  
  
}
# Run the application 
shinyApp(ui = ui, server = server)

